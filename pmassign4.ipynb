{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0e5ea1-804b-4189-8450-6650cb3fa8ea",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "### Gagana Uday Kumar (WOV796)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52c609-1c19-4e8d-8935-2a5bf047f8c7",
   "metadata": {},
   "source": [
    "### 3. We now review k-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94f6e5-5080-43db-a859-a3d444dbba43",
   "metadata": {},
   "source": [
    "### (a) Explain how k-fold cross-validation is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e42697-55c1-4591-98d9-18faf461b1fc",
   "metadata": {},
   "source": [
    "K-fold cross-validation involves splitting the dataset into k subsets. The model is trained k times, each time using a different subset as the validation set and the remaining data as the training set. Performance metrics are calculated for each iteration, and the average performance across all iterations is used to evaluate the model's performance. This method helps assess the model's generalization ability and reduces the risk of overfitting or underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cce549-aff2-412e-8196-74275818cd40",
   "metadata": {},
   "source": [
    "### (b) What are the advantages and disadvantages of k-fold crossvalidation relative to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85afa34-98fc-4cec-86d6-2a4246703a64",
   "metadata": {},
   "source": [
    "### i. The validation set approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d7c9ed-30df-4eda-9051-4375c25a610e",
   "metadata": {},
   "source": [
    "K-fold cross-validation offers several advantages over the validation set approach. Firstly, it maximizes the utilization of available data by partitioning the dataset into k equal-sized folds, ensuring that each data point is used for both training and validation across different folds. This leads to a more robust estimation of model performance, as it reduces the risk of overfitting to a specific validation set. Additionally, k-fold cross-validation provides a more stable estimate of model performance by averaging the results obtained from multiple rounds of training and validation with different subsets of data. This mitigates the variability associated with using a single validation set and provides a more reliable assessment of the model's generalization ability.\n",
    "\n",
    "However, k-fold cross-validation also comes with some drawbacks compared to the validation set approach. Firstly, it entails a higher computational cost since the model needs to be trained and evaluated k times, which can be resource-intensive for large datasets or complex models. This increased computational burden may not be feasible in scenarios where computational resources are limited. Moreover, the training time escalates with the number of folds, further exacerbating the computational overhead. Secondly, implementing k-fold cross-validation requires additional programming and handling of multiple folds, introducing complexity to the code compared to the simpler validation set approach. This complexity may pose challenges, particularly for beginners or when integrating cross-validation into existing workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee20fc9-7f99-424c-828f-332ee1777ef6",
   "metadata": {},
   "source": [
    "### ii. LOOCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8740d-d978-4633-abb8-46682060f3ff",
   "metadata": {},
   "source": [
    "K-fold cross-validation (KCV) and Leave-One-Out Cross-Validation (LOOCV) are two commonly used techniques for estimating the performance of machine learning models. KCV divides the dataset into k subsets or folds, trains the model k times using k-1 folds for training and one fold for validation, and then averages the results. In contrast, LOOCV partitions the dataset into n subsets, where n is the number of instances in the dataset, and trains the model n times, each time leaving out one instance for validation.\n",
    "\n",
    "One advantage of KCV over LOOCV is its reduced computational complexity. KCV typically requires fewer iterations compared to LOOCV, as the number of folds (k) is usually much smaller than the number of instances (n). This results in faster model evaluation, making KCV more practical for larger datasets. Additionally, KCV tends to provide a more stable estimate of model performance than LOOCV. Since KCV averages the results over multiple iterations with different subsets of data, it reduces the variance in the performance estimate and provides a more reliable assessment of the model's generalization ability.\n",
    "\n",
    "However, KCV also has some disadvantages compared to LOOCV. One limitation is that KCV may introduce higher bias into the performance estimate, especially when the dataset is small. With a smaller number of folds, each training set may not be representative of the entire dataset, leading to a biased evaluation of the model. Additionally, the choice of the number of folds (k) in KCV can impact the performance estimate. Selecting an inappropriate value for k may result in either overfitting or underfitting of the model to the data, affecting the reliability of the performance estimate. In contrast, LOOCV does not suffer from bias introduced by the choice of folds and provides an unbiased estimate of model performance, albeit at a higher computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f574acee-2f69-4e95-be14-48686554f2a7",
   "metadata": {},
   "source": [
    "### 5. In Chapter 4, we used logistic regression to predict the probability of default using income and balance on the Default data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71ceb83-98e4-407b-97b3-ce7a0234e417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS, summarize\n",
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "from sklearn.discriminant_analysis import \\\n",
    "(LinearDiscriminantAnalysis as LDA ,\n",
    "QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe2f7c44-f229-40eb-967a-c8b5be3e5d23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>711.555020</td>\n",
       "      <td>52992.378914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>757.962918</td>\n",
       "      <td>19660.721768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>845.411989</td>\n",
       "      <td>58636.156984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1569.009053</td>\n",
       "      <td>36669.112365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>200.922183</td>\n",
       "      <td>16862.952321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     default student      balance        income\n",
       "0         No      No   729.526495  44361.625074\n",
       "1         No     Yes   817.180407  12106.134700\n",
       "2         No      No  1073.549164  31767.138947\n",
       "3         No      No   529.250605  35704.493935\n",
       "4         No      No   785.655883  38463.495879\n",
       "...      ...     ...          ...           ...\n",
       "9995      No      No   711.555020  52992.378914\n",
       "9996      No      No   757.962918  19660.721768\n",
       "9997      No      No   845.411989  58636.156984\n",
       "9998      No      No  1569.009053  36669.112365\n",
       "9999      No     Yes   200.922183  16862.952321\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "De = pd.read_csv('Default.csv',na_values=['?']).dropna()\n",
    "De"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b140c050-8bcd-4a87-a29a-d1c945211cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>835.374886</td>\n",
       "      <td>33516.981876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>483.714985</td>\n",
       "      <td>13336.639563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>771.967729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>481.731105</td>\n",
       "      <td>21340.462903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>823.636973</td>\n",
       "      <td>34552.644802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1166.308386</td>\n",
       "      <td>43807.729272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2654.322576</td>\n",
       "      <td>73554.233495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            balance        income\n",
       "count  10000.000000  10000.000000\n",
       "mean     835.374886  33516.981876\n",
       "std      483.714985  13336.639563\n",
       "min        0.000000    771.967729\n",
       "25%      481.731105  21340.462903\n",
       "50%      823.636973  34552.644802\n",
       "75%     1166.308386  43807.729272\n",
       "max     2654.322576  73554.233495"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "De.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49085700-3f6b-45ff-815c-e6d71e662518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   default  10000 non-null  object \n",
      " 1   student  10000 non-null  object \n",
      " 2   balance  10000 non-null  float64\n",
      " 3   income   10000 non-null  float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "De.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9145d3e6-8cf5-4a6e-a29f-67fa6937e14c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     9667\n",
       "Yes     333\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "De[\"default\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1ff7dea-69cc-4f03-a894-a09dc8434a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "De['default'].replace({'Yes': 1, 'No': 0}, inplace=True)\n",
    "De['default'] = pd.to_numeric(De['default'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43f0fc03-4953-4bc8-bc54-bcc1e8b37269",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   default  10000 non-null  int64  \n",
      " 1   student  10000 non-null  object \n",
      " 2   balance  10000 non-null  float64\n",
      " 3   income   10000 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "De.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5547bb-2721-44a6-b9f0-0d5cc1f31ade",
   "metadata": {},
   "source": [
    "### (a) Fit a logistic regression model that uses income and balance to predict default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98b9ef86-5daa-4612-ab9a-1bb9c898d484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39664f69-b8ae-4348-8efd-9d171236a6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-11.540500</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>-26.544</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.835</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                coef   std err       z  P>|z|\n",
       "intercept -11.540500  0.435000 -26.544    0.0\n",
       "balance     0.005600  0.000000  24.835    0.0\n",
       "income      0.000021  0.000005   4.174    0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvars = De.columns.drop(['default', 'student',])\n",
    "design = MS(allvars)\n",
    "X = design.fit_transform(De)\n",
    "y = De.default == 1\n",
    "glm = sm.GLM(y,X, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "summarize(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2441edb4-fcc7-4a0d-9c1e-039049d89209",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [[2.08091984e-05 5.64710797e-03]]\n"
     ]
    }
   ],
   "source": [
    "X = De[['income', 'balance']]\n",
    "y = De['default']\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "print(\"Coefficients:\", model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dcff71-73a8-40a4-b66c-d63a7fd018ee",
   "metadata": {},
   "source": [
    "### (b) Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f5c07-1349-4bf2-9381-f087ea6880fa",
   "metadata": {},
   "source": [
    "### i. Split the sample set into a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50bcddcd-ba80-470f-ace3-167c1142a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fb6759-70b0-4c83-8fd7-d1adfeecef8c",
   "metadata": {},
   "source": [
    "### ii. Fit a multiple logistic regression model using only the training observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dff249d-b432-47f9-b503-41532937ca7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8fbaf9-f9ac-4971-a5bc-473a1c8439a1",
   "metadata": {},
   "source": [
    "### iii. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "057eddca-49a3-4390-9d94-ad6675090b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9750f14-6bf2-47a4-868b-cf67546df485",
   "metadata": {},
   "source": [
    "### iv. Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17f9303c-dd3f-4b55-9822-998382711499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9655\n",
      "Validation Set Error: 0.034499999999999975\n"
     ]
    }
   ],
   "source": [
    "validation_error = 1 - accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Validation Set Error:\", validation_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ede3be-c0cf-4bda-a889-4f7eb426e317",
   "metadata": {},
   "source": [
    "### (c) Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98419df4-1729-4308-b729-ff9f674dae47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test size 0.25: 0.9724\n",
      "Validation Set Error for test size 0.25: 0.027599999999999958\n",
      "Accuracy for test size 0.30: 0.9683333333333334\n",
      "Validation Set Error for test size 0.30: 0.03166666666666662\n",
      "Accuracy for test size 0.35: 0.9731428571428572\n",
      "Validation Set Error for test size 0.35: 0.0268571428571428\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "validation_error = 1 - accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy for test size 0.25:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Validation Set Error for test size 0.25:\", validation_error)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "validation_error = 1 - accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy for test size 0.30:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Validation Set Error for test size 0.30:\", validation_error)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.35, random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "validation_error = 1 - accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy for test size 0.35:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Validation Set Error for test size 0.35:\", validation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd7cb6a-b320-4356-8da0-4ce11e912d86",
   "metadata": {},
   "source": [
    "### (d) Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4308d012-2c89-42ee-866a-014b3baacf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9695\n",
      "Validation Set Error:  0.03049999999999997\n"
     ]
    }
   ],
   "source": [
    "X = pd.concat([De[['income', 'balance']], pd.get_dummies(De['student'], drop_first=True)], axis=1)\n",
    "y = De['default']\n",
    "\n",
    "validation_errors = []\n",
    "\n",
    "\n",
    "# Step i: Split the sample set into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=i*10)  # Change random_state value\n",
    "    \n",
    "# Step ii: Fit a multiple logistic regression model using only the training observations\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "    \n",
    "# Step iii: Obtain predictions for the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "    \n",
    "# Step iv: Compute the validation set error\n",
    "validation_error = 1 - accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"Validation Set Error: \", validation_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf81def-304a-48a3-b49f-8984abd4e8ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "Including student in the model does not improve the test erro rate much but we can see very little difference in the test error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef833c-33c6-4819-97da-97764a0bebef",
   "metadata": {},
   "source": [
    "### 6. We continue to consider the use of a logistic regression model to predict the probability of default using income and balance on the Default data set. In particular, we will now compute estimates for the standard errors of the income and balance logistic regression coefficients in two different ways: (1) using the bootstrap, and (2) using the standard formula for computing the standard errors in the sm.GLM() function. Do not forget to set a random seed before beginning your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9fbe79-3a8c-4442-871e-e671c9fa4bc2",
   "metadata": {},
   "source": [
    "### (a) Using the summarize() and sm.GLM() functions, determine the estimated standard errors for the coefficients associated with income and balance in a multiple logistic regression model that uses both predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ce378429-dbff-4dcc-89d9-ba1245b5fffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Errors:\n",
      "Income: 4.985245458257281e-06\n",
      "Balance: 0.0002273813844021027\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>-0.0002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-33.672</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.291</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>-3.7531</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>-24.580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef   std err       z  P>|z|\n",
       "income  -0.0002  0.000005 -33.672    0.0\n",
       "balance  0.0028  0.000000  22.291    0.0\n",
       "Yes     -3.7531  0.153000 -24.580    0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm = sm.GLM(y,X, family=sm.families.Binomial())\n",
    "results = glm.fit()\n",
    "\n",
    "print(\"Standard Errors:\")\n",
    "print(\"Income:\", standard_errors['income'])\n",
    "print(\"Balance:\", standard_errors['balance'])\n",
    "summarize(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b0930-1c7a-4d55-9ee3-35353f0e1273",
   "metadata": {},
   "source": [
    "### (b) Write a function, boot_fn(), that takes as input the Default data set as well as an index of the observations, and that outputs the coefficient estimates for income and balance in the multiple logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e88c80e7-a015-4e0a-beaa-6d79147f1bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_fn(data, index):\n",
    "    # Extract subset of data based on index\n",
    "    subset_data = data.iloc[index]\n",
    "    \n",
    "    # Fit logistic regression model using subset of data\n",
    "    logit_model = sm.GLM.from_formula('default ~ income + balance', data=subset_data, family=sm.families.Binomial()).fit()\n",
    "    \n",
    "    # Return coefficient estimates for income and balance\n",
    "    return logit_model.params['income'], logit_model.params['balance']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d93be8-6791-431c-ae67-02499430852f",
   "metadata": {},
   "source": [
    "### (c) Following the bootstrap example in the lab, use your boot_fn() function to estimate the standard errors of the logistic regression coefficients for income and balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14c5e69e-d254-48a7-a2df-f8ca5bb8647c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Errors:\n",
      "Income: 2.0869252932309845e-05\n",
      "Balance: 0.005653063123311437\n"
     ]
    }
   ],
   "source": [
    "def bootstrap(data, num_iterations):\n",
    "    num_obs = len(data)\n",
    "    standard_errors_income = []\n",
    "    standard_errors_balance = []\n",
    "    \n",
    "    # Iterate through bootstrap iterations\n",
    "    for _ in range(num_iterations):\n",
    "        # Generate bootstrap sample indices\n",
    "        bootstrap_indices = np.random.choice(num_obs, size=num_obs, replace=True)\n",
    "        \n",
    "        # Calculate standard errors using boot_fn\n",
    "        se_income, se_balance = boot_fn(data, bootstrap_indices)\n",
    "        standard_errors_income.append(se_income)\n",
    "        standard_errors_balance.append(se_balance)\n",
    "    \n",
    "    # Calculate average standard errors\n",
    "    avg_se_income = np.mean(standard_errors_income)\n",
    "    avg_se_balance = np.mean(standard_errors_balance)\n",
    "    \n",
    "    return avg_se_income, avg_se_balance\n",
    "\n",
    "# Call bootstrap function\n",
    "standard_errors_income, standard_errors_balance = bootstrap(De, num_iterations=1000)\n",
    "\n",
    "# Print standard errors\n",
    "print(\"Standard Errors:\")\n",
    "print(\"Income:\", standard_errors_income)\n",
    "print(\"Balance:\", standard_errors_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166ccf73-7fca-4637-9c6a-8fee3a4b9133",
   "metadata": {},
   "source": [
    "### (d) Comment on the estimated standard errors obtained using the sm.GLM() function and using the bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cc2d49-6181-420c-b130-6a53a6369859",
   "metadata": {},
   "source": [
    "We can observe that the standard errors obtained using the bootstrap are generally larger compared to those obtained directly from the sm.GLM() function. This difference is expected because the bootstrap method is inherently more robust and accounts for the variability in the data by resampling. Therefore, it tends to provide more conservative estimates of the standard errors.\n",
    "\n",
    "In this case, the larger standard errors obtained from the bootstrap indicate that there is more uncertainty associated with the coefficient estimates for both income and balance when using the bootstrap method. This suggests that the original standard errors obtained from the sm.GLM() function may have underestimated the uncertainty in the coefficient estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d082f71b-40df-45a4-8674-7fb978f9e695",
   "metadata": {},
   "source": [
    "### 9. We will now consider the Boston housing data set, from the ISLP library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d8c13de1-c4bc-4c54-87e6-ec3afe0fe7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>502</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>503</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>504</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>505</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>506</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     crim    zn  indus  chas    nox     rm   age     dis  rad  \\\n",
       "0             1  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1   \n",
       "1             2  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2   \n",
       "2             3  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2   \n",
       "3             4  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3   \n",
       "4             5  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3   \n",
       "..          ...      ...   ...    ...   ...    ...    ...   ...     ...  ...   \n",
       "501         502  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1   \n",
       "502         503  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1   \n",
       "503         504  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1   \n",
       "504         505  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1   \n",
       "505         506  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1   \n",
       "\n",
       "     tax  ptratio  lstat  medv  \n",
       "0    296     15.3   4.98  24.0  \n",
       "1    242     17.8   9.14  21.6  \n",
       "2    242     17.8   4.03  34.7  \n",
       "3    222     18.7   2.94  33.4  \n",
       "4    222     18.7   5.33  36.2  \n",
       "..   ...      ...    ...   ...  \n",
       "501  273     21.0   9.67  22.4  \n",
       "502  273     21.0   9.08  20.6  \n",
       "503  273     21.0   5.64  23.9  \n",
       "504  273     21.0   6.48  22.0  \n",
       "505  273     21.0   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Boston = pd.read_csv('Boston.csv',na_values=['?']).dropna()\n",
    "Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b037c1b3-b971-4122-9258-797227d8ed62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  506 non-null    int64  \n",
      " 1   crim        506 non-null    float64\n",
      " 2   zn          506 non-null    float64\n",
      " 3   indus       506 non-null    float64\n",
      " 4   chas        506 non-null    int64  \n",
      " 5   nox         506 non-null    float64\n",
      " 6   rm          506 non-null    float64\n",
      " 7   age         506 non-null    float64\n",
      " 8   dis         506 non-null    float64\n",
      " 9   rad         506 non-null    int64  \n",
      " 10  tax         506 non-null    int64  \n",
      " 11  ptratio     506 non-null    float64\n",
      " 12  lstat       506 non-null    float64\n",
      " 13  medv        506 non-null    float64\n",
      "dtypes: float64(10), int64(4)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "Boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15b18c12-4179-4563-8e37-597dae0bfe98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>253.500000</td>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>146.213884</td>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>127.250000</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>253.500000</td>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>379.750000</td>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        crim          zn       indus        chas         nox  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean   253.500000    3.613524   11.363636   11.136779    0.069170    0.554695   \n",
       "std    146.213884    8.601545   23.322453    6.860353    0.253994    0.115878   \n",
       "min      1.000000    0.006320    0.000000    0.460000    0.000000    0.385000   \n",
       "25%    127.250000    0.082045    0.000000    5.190000    0.000000    0.449000   \n",
       "50%    253.500000    0.256510    0.000000    9.690000    0.000000    0.538000   \n",
       "75%    379.750000    3.677083   12.500000   18.100000    0.000000    0.624000   \n",
       "max    506.000000   88.976200  100.000000   27.740000    1.000000    0.871000   \n",
       "\n",
       "               rm         age         dis         rad         tax     ptratio  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     6.284634   68.574901    3.795043    9.549407  408.237154   18.455534   \n",
       "std      0.702617   28.148861    2.105710    8.707259  168.537116    2.164946   \n",
       "min      3.561000    2.900000    1.129600    1.000000  187.000000   12.600000   \n",
       "25%      5.885500   45.025000    2.100175    4.000000  279.000000   17.400000   \n",
       "50%      6.208500   77.500000    3.207450    5.000000  330.000000   19.050000   \n",
       "75%      6.623500   94.075000    5.188425   24.000000  666.000000   20.200000   \n",
       "max      8.780000  100.000000   12.126500   24.000000  711.000000   22.000000   \n",
       "\n",
       "            lstat        medv  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Boston.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a87c29-7a64-47cd-bdbd-73f14a2b5f2d",
   "metadata": {},
   "source": [
    "### (a) Based on this data set, provide an estimate for the population mean of medv. Call this estimate $\\hat{μ}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6130d0b2-65b1-4c9b-b066-d0b1e1cddca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated population mean of medv (μ̂): 22.532806324110677\n"
     ]
    }
   ],
   "source": [
    "sample_mean = Boston['medv'].mean()\n",
    "\n",
    "# Print the estimated population mean\n",
    "print(\"Estimated population mean of medv (μ̂):\", sample_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896eefa7-caae-432a-82c8-f573bcf435e4",
   "metadata": {},
   "source": [
    "### (b) Provide an estimate of the standard error of $\\hat{μ}$. Interpret this result. Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "36dde833-ab8c-4d13-8f5b-3973897fae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated standard error of the sample mean (SE): 0.4088611474975351\n"
     ]
    }
   ],
   "source": [
    "# Calculate sample standard deviation\n",
    "sample_std = Boston['medv'].std()\n",
    "\n",
    "# Determine the number of observations\n",
    "n = Boston['medv'].count()\n",
    "\n",
    "# Calculate the standard error of the sample mean\n",
    "SE = sample_std / np.sqrt(n)\n",
    "\n",
    "# Print the estimate of the standard error\n",
    "print(\"Estimated standard error of the sample mean (SE):\", SE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf6e0d4-5133-4b42-a90c-56b0c4cdb8b3",
   "metadata": {},
   "source": [
    "### (c) Now estimate the standard error of $\\hat{μ}$ using the bootstrap. How does this compare to your answer from (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c007c18a-6c8f-47cc-b8b1-984fa71b80cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of standard error of sample mean of medv (using bootstrap) is: 0.40420840484829434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "def boot(df):\n",
    "    return resample(df)\n",
    "\n",
    "B = 1000\n",
    "sample_mean = []\n",
    "\n",
    "for i in range(B):\n",
    "    df = boot(Boston)\n",
    "    sample_mean.append(df['medv'].mean())\n",
    "\n",
    "print(\"Estimate of standard error of sample mean of medv (using bootstrap) is: \" +str(np.std(sample_mean, ddof=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02627ca7-66cf-4aab-af3f-79fa98900821",
   "metadata": {},
   "source": [
    "### (d) Based on your bootstrap estimate from (c), provide a 95 % confidence interval for the mean of medv. Compare it to the results obtained by using Boston['medv'].std() and the two standard error rule (3.9). Hint: You can approximate a 95 % confidence interval using the formula [$\\hat{μ}$ − 2SE($\\hat{μ}$), $\\hat{μ}$ + 2SE($\\hat{μ}$)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0244d766-c66d-461b-9fde-4d702ce8e9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence interval using bootstrap is: (22.12348,22.942120000000003)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=55.11114583037392, pvalue=9.370623727132662e-216, df=505)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "print(\"95% Confidence interval using bootstrap is: (\" + str(22.5328 - 0.40932) + \",\" + str(22.5328 + 0.40932) + \")\")\n",
    "stats.ttest_1samp(a= Boston['medv'], popmean=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948a5053-8433-4490-bb47-1ad44fe0d4ea",
   "metadata": {},
   "source": [
    "### (e) Based on this data set, provide an estimate, $\\hat{μ}_{med}$, for the median value of medv in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "71a0fcb2-ae84-4f34-be3f-bdd2264d0c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate for population median of medv is: 21.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimate for population median of medv is: \" +str(Boston['medv'].median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98819ac5-185b-462c-889a-ea51e716ad83",
   "metadata": {},
   "source": [
    "### (f) We now would like to estimate the standard error of $\\hat{μ}_{med}$. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "172b58c5-3fae-4b50-baa9-393ddeb97e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of standard error of sample median of medv (using bootstrap) is: 0.3787820657757612\n"
     ]
    }
   ],
   "source": [
    "B = 1000\n",
    "sample_median = []\n",
    "\n",
    "for i in range(B):\n",
    "    df = boot(Boston)\n",
    "    sample_median.append(df['medv'].median())\n",
    "\n",
    "print(\"Estimate of standard error of sample median of medv (using bootstrap) is: \" +str(np.std(sample_median, ddof=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c14fe7-0bf1-402b-ac80-00912dc38bab",
   "metadata": {},
   "source": [
    "### (g) Based on this data set, provide an estimate for the tenth percentile of medv in Boston census tracts. Call this quantity $\\hat{μ}_{0.1}$. (You can use the np.percentile() function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "64f00f81-6a28-4cb0-a05c-9c54917b4943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate for the tenth percentile of medv is: 12.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimate for the tenth percentile of medv is: \" +str(Boston['medv'].quantile(q=0.1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fd328-baba-480e-82d8-fe2b551b4f4a",
   "metadata": {},
   "source": [
    "### (h) Use the bootstrap to estimate the standard error of $\\hat{μ}_{0.1}$ . Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "68838d50-146f-4903-820a-af95e5d31f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of standard error for the tenth percentile of medv (using bootstrap) is: 0.5070456935379052\n"
     ]
    }
   ],
   "source": [
    "B = 1000\n",
    "sample_percentile = []\n",
    "\n",
    "for i in range(B):\n",
    "    df = boot(Boston)\n",
    "    sample_percentile.append(df['medv'].quantile(q=0.1))\n",
    "\n",
    "print(\"Estimate of standard error for the tenth percentile of medv (using bootstrap) is: \"\n",
    "      +str(np.std(sample_percentile, ddof=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fd5a3-de24-4f9e-aed3-c60120ff470e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
